{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Texto alternativo](nlp.jpg \"Texto opcional del título\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCL0r4ap2H4T"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<h1 style=\"color: #ffffff; font-size: 40px; font-weight: bold; text-align: center;\n",
        "background-color: #2e2e2e; border-radius: 6px; padding: 20px; box-shadow: 3px 3px 10px #000000;\n",
        "text-shadow: 0 0 5px #2ecc71, 0 0 10px #2ecc71, 0 0 20px #2ecc71, 0 0 40px #0e0e0e,\n",
        "0 0 80px #0e0e0e, 0 0 90px #0e0e0e;\">\n",
        "  Construcción de un modelo markoviano de máxima entropía\n",
        "</h1>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FaYXYmy5ahC"
      },
      "outputs": [],
      "source": [
        "!pip install conllu\n",
        "!pip install stanza\n",
        "!git clone https://github.com/UniversalDependencies/UD_Spanish-AnCora.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Oi9R1bn2Qmg"
      },
      "source": [
        "### Entrenamiento del modelo - cálculo de conteos\n",
        "\n",
        "Parta este modelo consideramos el cálculo de las probabilidades:\n",
        "\n",
        "$$P(t_i | w_i, t_{i-1}) =\\frac{C(w_i, t_i, t_{i-1})}{C(w_i, t_{i-1})} $$\n",
        "\n",
        "* `uniqueFeatureDict` $C(tag|word,prevtag) = C(w_i, t_i, t_{i-1})$\n",
        "* `contextDict` $C(word,prevtag) = C(w_i, t_{i-1})$\n",
        "\n",
        "En este caso cuando consideremos el primer elemento de una frase $w_0$, no existirá un elemento anterior $w_{-1}$ y por lo tanto, tampoco una etiqueta previa $t_{-1}$, podemos modelar este problema asumiendo que existe una etiqueta \"None\", para estos casos:\n",
        "\n",
        "$$P(t_0|w_0,t_{-1}) = P(t_0|w_0,\\text{\"None\"})$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0riVspXk1nHl"
      },
      "outputs": [],
      "source": [
        "from conllu import parse_incr\n",
        "\n",
        "uniqueFeatureDict = {}\n",
        "contextDict = {}\n",
        "\n",
        "tagtype = 'upos'\n",
        "data_file = open(\"UD_Spanish-AnCora/es_ancora-ud-train.conllu\", \"r\", encoding=\"utf-8\")\n",
        "\n",
        "# Calculando conteos (pre-probabilidades)\n",
        "for tokenlist in parse_incr(data_file):\n",
        "  prevtag = \"None\"\n",
        "  for token in tokenlist:\n",
        "    tag = token[tagtype]\n",
        "    word = token['form'].lower()\n",
        "    #C(tag|word,prevtag)\n",
        "    largeKey = tag+'|'+word+','+prevtag\n",
        "    if largeKey in uniqueFeatureDict.keys():\n",
        "      uniqueFeatureDict[largeKey]+=1\n",
        "    else:\n",
        "      uniqueFeatureDict[largeKey]=1\n",
        "    key = word+','+prevtag\n",
        "    if key in contextDict.keys():\n",
        "      contextDict[key]+=1\n",
        "    else:\n",
        "      contextDict[key]=1\n",
        "    #print(largeKey, key, '\\n')\n",
        "    prevtag=tag"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6npPBeu_8OzK"
      },
      "source": [
        "### Entrenamiento del modelo - cálculo de probabilidades\n",
        "\n",
        "$$P(t_i|w_i, t_{i-1}) = \\frac{C(t_i, w_i, t_{i-1})}{C(w_i, t_{i-1})}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywGEbMTw73NU"
      },
      "outputs": [],
      "source": [
        "posteriorProbDict = {}\n",
        "\n",
        "for key in uniqueFeatureDict.keys():\n",
        "  if len(key.split('|'))==3:\n",
        "    posteriorProbDict[key] = uniqueFeatureDict[key]/contextDict['|'+key.split('|')[-1]]\n",
        "  else:\n",
        "    posteriorProbDict[key] = uniqueFeatureDict[key]/contextDict[key.split('|')[1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eA9wqVQPBiVN"
      },
      "outputs": [],
      "source": [
        "# Aquí verificamos que todas las probabilidades\n",
        "# por cada contexto 'word,prevtag' suman 1.0\n",
        "\n",
        "for base_context in contextDict.keys():\n",
        "  countprob = 0\n",
        "  items = 0\n",
        "  for key in posteriorProbDict.keys():\n",
        "    if len(key.split('|'))==3:\n",
        "      if '|'+key.split('|')[-1]==base_context:\n",
        "        countprob+=posteriorProbDict[key]\n",
        "        items+=1\n",
        "    else:\n",
        "      if key.split('|')[1]==base_context:\n",
        "        countprob+=posteriorProbDict[key]\n",
        "        items+=1\n",
        "  print(base_context, items, countprob)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leSuajlOA-3c"
      },
      "source": [
        "### Distribución inicial de estados latentes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "nU4ShPmDQRp0",
        "outputId": "36c33c52-c49a-482b-e7b4-240e25bbf92f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ADJ': 9,\n",
              " 'ADP': 8,\n",
              " 'ADV': 1,\n",
              " 'AUX': 14,\n",
              " 'CCONJ': 4,\n",
              " 'DET': 12,\n",
              " 'INTJ': 15,\n",
              " 'NOUN': 2,\n",
              " 'NUM': 7,\n",
              " 'PART': 3,\n",
              " 'PRON': 5,\n",
              " 'PROPN': 0,\n",
              " 'PUNCT': 10,\n",
              " 'SCONJ': 6,\n",
              " 'SYM': 16,\n",
              " 'VERB': 11,\n",
              " '_': 13}"
            ]
          },
          "execution_count": 40,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# identificamos las categorias gramaticales 'upos' unicas en el corpus\n",
        "stateSet = {'ADJ',\n",
        " 'ADP',\n",
        " 'ADV',\n",
        " 'AUX',\n",
        " 'CCONJ',\n",
        " 'DET',\n",
        " 'INTJ',\n",
        " 'NOUN',\n",
        " 'NUM',\n",
        " 'PART',\n",
        " 'PRON',\n",
        " 'PROPN',\n",
        " 'PUNCT',\n",
        " 'SCONJ',\n",
        " 'SYM',\n",
        " 'VERB',\n",
        " '_'}\n",
        "# enumeramos las categorias con numeros para asignar a\n",
        "# las columnas de la matriz de Viterbi\n",
        "tagStateDict = {}\n",
        "for i, state in enumerate(stateSet):\n",
        "  tagStateDict[state] = i\n",
        "tagStateDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "oACerPVe_Awz",
        "outputId": "ee5372eb-1f00-4b05-81b1-68fabcaa28d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ADJ': 0.010136315973435861,\n",
              " 'ADP': 0.1574274729115694,\n",
              " 'ADV': 0.07577770010485844,\n",
              " 'AUX': 0.022789234533379936,\n",
              " 'CCONJ': 0.036980076896190144,\n",
              " 'DET': 0.34799021321216356,\n",
              " 'INTJ': 0.0020272631946871723,\n",
              " 'NOUN': 0.025026214610276126,\n",
              " 'NUM': 0.0068507514854945824,\n",
              " 'PART': 0.002446696959105208,\n",
              " 'PRON': 0.04173365955959455,\n",
              " 'PROPN': 0.10506815798671792,\n",
              " 'PUNCT': 0.09143656064313177,\n",
              " 'SCONJ': 0.027123383432366307,\n",
              " 'SYM': 0.0004893393918210416,\n",
              " 'VERB': 0.04557846906675987,\n",
              " '_': 0.0011184900384480952}"
            ]
          },
          "execution_count": 41,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "initTagStateProb = {} # \\rho_i^{(0)}\n",
        "from conllu import parse_incr\n",
        "wordList = []\n",
        "data_file = open(\"UD_Spanish-AnCora/es_ancora-ud-train.conllu\", \"r\", encoding=\"utf-8\")\n",
        "count = 0 # cuenta la longitud del corpus\n",
        "for tokenlist in parse_incr(data_file):\n",
        "  count += 1\n",
        "  tag = tokenlist[0]['upos']\n",
        "  if tag in initTagStateProb.keys():\n",
        "    initTagStateProb[tag] += 1\n",
        "  else:\n",
        "    initTagStateProb[tag] = 1\n",
        "\n",
        "for key in initTagStateProb.keys():\n",
        "  initTagStateProb[key] /= count\n",
        "\n",
        "initTagStateProb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neEbST9IDq8f"
      },
      "source": [
        "### Construcción del algoritmo de Viterbi\n",
        "\n",
        "Dada una secuencia de palabras $\\{p_1, p_2, \\dots, p_n \\}$, y un conjunto de categorias gramaticales dadas por la convención `upos`, se considera la matriz de probabilidades de Viterbi así:\n",
        "\n",
        "$$\n",
        "\\begin{array}{c c}\n",
        "\\begin{array}{c c c c}\n",
        "\\text{ADJ} \\\\\n",
        "\\text{ADV}\\\\\n",
        "\\text{PRON} \\\\\n",
        "\\vdots \\\\\n",
        "{}\n",
        "\\end{array}\n",
        "&\n",
        "\\left[\n",
        "\\begin{array}{c c c c}\n",
        "\\nu_1(\\text{ADJ}) & \\nu_2(\\text{ADJ}) & \\dots  & \\nu_n(\\text{ADJ})\\\\\n",
        "\\nu_1(\\text{ADV}) & \\nu_2(\\text{ADV}) & \\dots  & \\nu_n(\\text{ADV})\\\\\n",
        "\\nu_1(\\text{PRON}) & \\nu_2(\\text{PRON}) & \\dots  & \\nu_n(\\text{PRON})\\\\\n",
        "\\vdots & \\vdots & \\dots & \\vdots \\\\ \\hdashline\n",
        "p_1 & p_2 & \\dots & p_n\n",
        "\\end{array}\n",
        "\\right]\n",
        "\\end{array}\n",
        "$$\n",
        "\n",
        "Donde las probabilidades de Viterbi en la primera columna (para una categoria $i$) están dadas por:\n",
        "\n",
        "$$\n",
        "\\nu_1(i) = \\underbrace{\\rho_i^{(0)}}_{\\text{probabilidad inicial}} \\times P(i \\vert p_1, \\text{\"None\"})\n",
        "$$\n",
        "\n",
        "y para las siguientes columnas:\n",
        "\n",
        "$$\n",
        "\\nu_{t}(j) = \\max_i \\{ \\overbrace{\\nu_{t-1}(i)}^{\\text{estado anterior}} \\times P(j \\vert p_t, i) \\}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "o7fDedW5BE-q",
        "outputId": "524b045a-f059-49b3-ee39-c416c4bf03a6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.1.0.json: 122kB [00:00, 9.28MB/s]                    \n",
            "2020-08-18 02:14:23 INFO: Downloading default packages for language: es (Spanish)...\n",
            "2020-08-18 02:14:25 INFO: File exists: /root/stanza_resources/es/default.zip.\n",
            "2020-08-18 02:14:31 INFO: Finished downloading models and saved to /root/stanza_resources.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import stanza\n",
        "stanza.download('es')\n",
        "nlp = stanza.Pipeline('es', processors='tokenize')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "X8yBXTq-PHGY",
        "outputId": "a20e1dff-14a4-463c-b2a0-db03c9fbcab6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.00000000e+00, 8.22024126e-03, 1.13643888e-04, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 3.39769972e-01, 5.94927966e-03, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.33820692e-01],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [3.47990213e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 3.33820692e-01, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
            ]
          },
          "execution_count": 52,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def ViterbiMatrix(secuencia, posteriorProbDict=posteriorProbDict, initTagStateProb=initTagStateProb):\n",
        "  doc = nlp(secuencia)\n",
        "  if len(doc.sentences)>1:\n",
        "    raise ValueError('secuencia must be a string!')\n",
        "  seq = [word.text for word in doc.sentences[0].words]\n",
        "  viterbiProb = np.zeros((17, len(seq)))\n",
        "\n",
        "  # inicialización primera columna\n",
        "  for tag in tagStateDict.keys():\n",
        "    tag_row = tagStateDict[tag]\n",
        "    key = tag+'|'+seq[0].lower()+','+\"None\"\n",
        "    try:\n",
        "      viterbiProb[tag_row, 0] = initTagStateProb[tag]*posteriorProbDict[key]\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "  # computo de las siguientes columnas\n",
        "  for col in range(1, len(seq)):\n",
        "    for tag in tagStateDict.keys():\n",
        "      tag_row = tagStateDict[tag]\n",
        "      possible_probs = []\n",
        "      for prevtag in tagStateDict.keys():\n",
        "        prevtag_row = tagStateDict[prevtag]\n",
        "        key = tag+'|'+seq[col].lower()+','+prevtag\n",
        "        try:\n",
        "          possible_probs.append(\n",
        "              viterbiProb[prevtag_row, col-1]*posteriorProbDict[key])\n",
        "        except:\n",
        "          possible_probs.append(0)\n",
        "      viterbiProb[tag_row, col] = max(possible_probs)\n",
        "\n",
        "  return viterbiProb\n",
        "\n",
        "ViterbiMatrix('el mundo es pequeño')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "XKC3bh60X3h3",
        "outputId": "cb65ae08-fdd4-4103-9572-6f77256bf247"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('el', 'DET'), ('mundo', 'NOUN'), ('es', 'AUX'), ('pequeño', 'ADJ')]"
            ]
          },
          "execution_count": 53,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def ViterbiTags(secuencia, posteriorProbDict=posteriorProbDict, initTagStateProb=initTagStateProb):\n",
        "  doc = nlp(secuencia)\n",
        "  if len(doc.sentences)>1:\n",
        "    raise ValueError('secuencia must be a string!')\n",
        "  seq = [word.text for word in doc.sentences[0].words]\n",
        "  viterbiProb = np.zeros((17, len(seq)))\n",
        "\n",
        "  # inicialización primera columna\n",
        "  for tag in tagStateDict.keys():\n",
        "    tag_row = tagStateDict[tag]\n",
        "    key = tag+'|'+seq[0].lower()+','+\"None\"\n",
        "    try:\n",
        "      viterbiProb[tag_row, 0] = initTagStateProb[tag]*posteriorProbDict[key]\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "\n",
        "  # computo de las siguientes columnas\n",
        "  for col in range(1, len(seq)):\n",
        "    for tag in tagStateDict.keys():\n",
        "      tag_row = tagStateDict[tag]\n",
        "      possible_probs = []\n",
        "      for prevtag in tagStateDict.keys():\n",
        "        prevtag_row = tagStateDict[prevtag]\n",
        "        key = tag+'|'+seq[col].lower()+','+prevtag\n",
        "        try:\n",
        "          possible_probs.append(\n",
        "              viterbiProb[prevtag_row, col-1]*posteriorProbDict[key])\n",
        "        except:\n",
        "          possible_probs.append(0)\n",
        "      viterbiProb[tag_row, col] = max(possible_probs)\n",
        "\n",
        "  # contruccion de secuencia de tags\n",
        "  res = []\n",
        "  for i, p in enumerate(seq):\n",
        "    for tag in tagStateDict.keys():\n",
        "      if tagStateDict[tag] == np.argmax(viterbiProb[:, i]):\n",
        "        res.append((p, tag))\n",
        "\n",
        "\n",
        "  return res\n",
        "\n",
        "ViterbiTags('el mundo es pequeño')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "4OjxWFgVZYKF",
        "outputId": "982899cc-8654-4a69-daff-7c0c1b2eb3d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('estos', 'DET'),\n",
              " ('instrumentos', 'NOUN'),\n",
              " ('han', 'AUX'),\n",
              " ('de', 'ADP'),\n",
              " ('rasgar', 'PROPN')]"
            ]
          },
          "execution_count": 54,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ViterbiTags('estos instrumentos han de rasgar')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
