{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Texto alternativo](nlp.jpg \"Texto opcional del título\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "<h1 style=\"color: #ffffff; font-size: 40px; font-weight: bold; text-align: center;\n",
        "background-color: #2e2e2e; border-radius: 6px; padding: 20px; box-shadow: 3px 3px 10px #000000;\n",
        "text-shadow: 0 0 5px #2ecc71, 0 0 10px #2ecc71, 0 0 20px #2ecc71, 0 0 40px #0e0e0e,\n",
        "0 0 80px #0e0e0e, 0 0 90px #0e0e0e;\">\n",
        "  NaiveBayes\n",
        "</h1>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iyAhmlbo24VQ"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "H7BKMjaR28jW"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['spam', 'ham']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.listdir('datasets/email/plaintext/corpus1')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSHovwBR1ZfA"
      },
      "source": [
        "## Preparación del corpus de emails"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "id": "w8P_ve0L0Gyu",
        "outputId": "94795fbe-f893-40b9-90d2-746ce90be8d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'datasets'...\n",
            "remote: Enumerating objects: 39, done.\u001b[K\n",
            "remote: Total 39 (delta 0), reused 0 (delta 0), pack-reused 39\u001b[K\n",
            "Receiving objects: 100% (39/39), 41.91 MiB | 15.53 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/pachocamacho1990/datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "id": "dJTtSZto1jC1",
        "outputId": "725116b6-35ad-4a1c-ecf4-f5f073c5e456"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5172"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = []\n",
        "clases = []\n",
        "#lectura de spam data\n",
        "for file in os.listdir('datasets/email/plaintext/corpus1/spam'):\n",
        "  with open('datasets/email/plaintext/corpus1/spam/'+file, encoding='latin-1') as f:\n",
        "    data.append(f.read())\n",
        "    clases.append('spam')\n",
        "#lectura de ham data\n",
        "for file in os.listdir('datasets/email/plaintext/corpus1/ham'):\n",
        "  with open('datasets/email/plaintext/corpus1/ham/'+file, encoding='latin-1') as f:\n",
        "    data.append(f.read())\n",
        "    clases.append('ham')\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NOb61Ik7MI-"
      },
      "source": [
        "## Construcción de modelo Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXXlUjrJ7DjR"
      },
      "source": [
        "### Tokenizador de Spacy\n",
        "\n",
        "* Documentación: https://spacy.io/api/tokenizer\n",
        "* ¿Cómo funciona el tokenizador? https://spacy.io/usage/linguistic-features#how-tokenizer-works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePmKCQpw4cqK"
      },
      "outputs": [],
      "source": [
        "from spacy.tokenizer import Tokenizer\n",
        "from spacy.lang.en import English\n",
        "\n",
        "nlp = English()\n",
        "tokenizer = Tokenizer(nlp.vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "oF1cGmZ293OA",
        "outputId": "17490c87-9c24-420f-e251-5324b2357bd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Subject:', 'brand', 'new', 'teenager', 'peeing', '\\n', 'you', 'don', \"'\", 't', 'know', 'me', 'from', 'adam', '.', ':', ')', 'iyakubonana', '\\n', 'nothing', 'that', 'you', 'have', 'not', 'given', 'away', 'will', 'ever', 'be', 'really', 'yours', '.', '\\n', 'i', 'don', \"'\", 't', 'deserve', 'this', 'award', ',', 'but', 'i', 'have', 'arthritis', ',', 'and', 'i', 'don', \"'\", 't', 'deserve', 'that', ',', 'either', '.', 'the', 'most', 'important', 'thing', 'a', 'father', 'can', 'do', 'for', 'his', 'children', 'is', 'to', 'love', 'their', 'mother', '.', '\\n', 'tricks', 'and', 'treachery', 'are', 'the', 'practice', 'of', 'fools', ',', 'that', 'don', \"'\", 't', 'have', 'brains', 'enough', 'to', 'be', 'honest', '.', '\\n', 'a', 'heart', 'that', 'loves', 'is', 'always', 'young', '.', '\\n', 'if', 'you', 'drink', ',', 'don', \"'\", 't', 'drive', '.', 'don', \"'\", 't', 'even', 'putt', '.', '\\n', 'husbands', 'never', 'become', 'good', 'they', 'merely', 'become', 'proficient', '.', '\\n', 'only', 'from', 'the', 'heart', 'can', 'you', 'touch', 'the', 'sky', '.', '\\n', 'even', 'if', 'it', 'is', 'to', 'be', ',', 'what', 'end', 'do', 'you', 'serve', 'by', 'running', 'to', 'distress', '?', 'it', 'is', 'a', 'terrible', 'thing', 'to', 'look', 'over', 'your', 'shoulder', 'when', 'you', 'are', 'trying', 'to', 'lead', '-', '-', 'and', 'find', 'no', 'one', 'there', '.', '\\n', 'i', 'hated', 'her', 'now', 'with', 'a', 'hatred', 'more', 'fatal', 'than', 'indifference', 'because', 'it', 'was', 'the', 'other', 'side', 'of', 'love', '.', '\\n', 'reading', 'makes', 'a', 'full', 'man', ',', 'meditation', 'a', 'profound', 'man', ',', 'discourse', 'a', 'clear', 'man', '.', '\\n', 'a', 'few', 'strong', 'instincts', 'and', 'a', 'few', 'plain', 'rules', 'suffice', 'us', '.', '\\n', 'we', 'are', 'all', 'sentenced', 'to', 'solitary', 'confinement', 'inside', 'our', 'own', 'skins', ',', 'for', 'life', '.', '\\n', 'eroticism', 'is', 'assenting', 'to', 'life', 'even', 'in', 'death', '.', '\\n', 'truly', 'great', 'friends', 'are', 'hard', 'to', 'find', ',', 'difficult', 'to', 'leave', ',', 'and', 'impossible', 'to', 'forget', '.', '\\n', 'the', 'weeping', 'of', 'an', 'heir', 'is', 'laughter', 'in', 'disguise', '.', 'the', 'harder', 'i', 'work', 'the', 'luckier', 'i', 'get', '.']\n"
          ]
        }
      ],
      "source": [
        "print([t.text for t in tokenizer(data[0])])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4i6IQGx7Tul"
      },
      "source": [
        "### Clase principal para el algoritmo\n",
        "\n",
        "Recuerda que la clase más probable viene dada por (en espacio de cómputo logarítmico):\n",
        "\n",
        "\n",
        "$$\\hat{c} = {\\arg \\max}_{(c)}\\log{P(c)}\n",
        " +\\sum_{i=1}^n\n",
        "\\log{ P(f_i \\vert c)}\n",
        "$$\n",
        "\n",
        "Donde, para evitar casos atípicos, usaremos el suavizado de Laplace así:\n",
        "\n",
        "$$\n",
        "P(f_i \\vert c) = \\frac{C(f_i, c)+1}{C(c) + \\vert V \\vert}\n",
        "$$\n",
        "\n",
        "siendo $\\vert V \\vert$ la longitud del vocabulario de nuestro conjunto de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTgbTusfyPHW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class NaiveBayesClassifier():\n",
        "  nlp = English()\n",
        "  tokenizer = Tokenizer(nlp.vocab)\n",
        "\n",
        "  def tokenize(self, doc):\n",
        "    return  [t.text.lower() for t in tokenizer(doc)]\n",
        "\n",
        "  def word_counts(self, words):\n",
        "    wordCount = {}\n",
        "    for w in words:\n",
        "      if w in wordCount.keys():\n",
        "        wordCount[w] += 1\n",
        "      else:\n",
        "        wordCount[w] = 1\n",
        "    return wordCount\n",
        "\n",
        "  def fit(self, data, clases):\n",
        "    n = len(data)\n",
        "    self.unique_clases = set(clases)\n",
        "    self.vocab = set()\n",
        "    self.classCount = {} #C(c)\n",
        "    self.log_classPriorProb = {} #P(c)\n",
        "    self.wordConditionalCounts = {} #C(w|c)\n",
        "    #conteos de clases\n",
        "    for c in clases:\n",
        "      if c in self.classCount.keys():\n",
        "        self.classCount[c] += 1\n",
        "      else:\n",
        "        self.classCount[c] = 1\n",
        "    # calculo de P(c)\n",
        "    for c in self.classCount.keys():\n",
        "      self.log_classPriorProb[c] = math.log(self.classCount[c]/n)\n",
        "      self.wordConditionalCounts[c] = {}\n",
        "    # calculo de C(w|c)\n",
        "    for text, c in zip(data, clases):\n",
        "      counts = self.word_counts(self.tokenize(text))\n",
        "      for word, count in counts.items():\n",
        "        if word not in self.vocab:\n",
        "          self.vocab.add(word)\n",
        "        if word not in self.wordConditionalCounts[c]:\n",
        "          self.wordConditionalCounts[c][word] = 0.0\n",
        "        self.wordConditionalCounts[c][word] += count\n",
        "\n",
        "  def predict(self, data):\n",
        "    results = []\n",
        "    for text in data:\n",
        "      words = set(self.tokenize(text))\n",
        "      scoreProb = {}\n",
        "      for word in words:\n",
        "        if word not in self.vocab: continue #ignoramos palabras nuevas\n",
        "        #suavizado Laplaciano para P(w|c)\n",
        "        for c in self.unique_clases:\n",
        "          log_wordClassProb = math.log(\n",
        "              (self.wordConditionalCounts[c].get(word, 0.0)+1)/(self.classCount[c]+len(self.vocab)))\n",
        "          scoreProb[c] = scoreProb.get(c, self.log_classPriorProb[c]) + log_wordClassProb\n",
        "      arg_maxprob = np.argmax(np.array(list(scoreProb.values())))\n",
        "      results.append(list(scoreProb.keys())[arg_maxprob])\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EE9Aus71bdUx"
      },
      "source": [
        "### Utilidades de Scikit Learn\n",
        "* `train_test_split`: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "\n",
        "* `accuracy_score`: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
        "\n",
        "* `precision_score`: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html\n",
        "\n",
        "* `recall_score`: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m95539uQZaDZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "data_train, data_test, clases_train, clases_test = train_test_split(data, clases, test_size=0.10, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Qrb-42APpHM"
      },
      "outputs": [],
      "source": [
        "classifier = NaiveBayesClassifier()\n",
        "classifier.fit(data_train, clases_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdzx7-5xXJfD"
      },
      "outputs": [],
      "source": [
        "clases_predict = classifier.predict(data_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "id": "0whDaiFwayf5",
        "outputId": "54ffe0bc-51ce-4f8b-b1eb-3145ad48ed46"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8552123552123552"
            ]
          },
          "execution_count": 130,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_score(clases_test, clases_predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "id": "FQM3QjN1dlIu",
        "outputId": "ade43f9a-8251-4686-db3a-da620d4d304e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.82876712, 1.        ])"
            ]
          },
          "execution_count": 131,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "precision_score(clases_test, clases_predict, average=None, zero_division=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "id": "KiWQMX0Jdmnt",
        "outputId": "202c982f-3abe-4b5c-f5e7-46e2bc624a22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1.        , 0.51612903])"
            ]
          },
          "execution_count": 132,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "recall_score(clases_test, clases_predict, average=None, zero_division=1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
